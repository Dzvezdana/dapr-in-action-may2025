{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoXVSenoEcMN"
   },
   "source": [
    "# Dapr in Action: From Core Concepts to AI Agents\n",
    "\n",
    "Welcome to the \"Dapr in Action: From Core Concepts to AI Agents\" workshop!\n",
    "\n",
    "This workshop provides a hands-on introduction to Dapr Agents through simple examples. By the end of this workshop, you will be able to:\n",
    "\n",
    "* Create and interact with LLMs using Dapr Agents\n",
    "* Build custom tools for agents to use\n",
    "* Implement the ReAct pattern (Reasoning + Action)\n",
    "* Create stateful workflows with multiple LLM steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYsgOsfWRnur"
   },
   "source": [
    "### Notebook 1. Basic LLM Usage & Understanding Response Objects\n",
    "\n",
    "This notebook demonstrates how to use the `HFHubChatClient` in [dapr-agents](https://github.com/dapr/dapr-agents/tree/main) for basic tasks. We will explore how to:\n",
    "\n",
    "* Initialize the Hugging Face Chat client.\n",
    "* Generate responses to simple prompts.\n",
    "* Use a `.prompty` file to provide context/history for enhanced generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtiywbjXOkwz"
   },
   "source": [
    "#### **[Only if you are using Google Colab]** Setting up dependencies\n",
    "\n",
    "First, let's install all the dependencies. Execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOK2gzazRjzZ"
   },
   "outputs": [],
   "source": [
    "!pip install dapr-agents==0.5.1\n",
    "!pip install yfinance>=0.2.61\n",
    "!pip install prompty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTCAD-Zoj6Ux"
   },
   "source": [
    "#### **[Only if you are using Google Colab]** Setting up secrets\n",
    "\n",
    "Next, we need to set the secrets. In Google Colab, in the left-side menu navigate to Secrets->Add new secret.\n",
    "\n",
    "Create two secrets with Notebook access called: `HUGGINGFACE_API_KEY` and `CURRENTS_API_KEY`.\n",
    "\n",
    "You can find their values [here](https://privatebin.net/?ec00cd7f2c464e55#8xMHSFNHyTrGe8f1DhyB62qCmb9RwrPoFExV5pWKXZEs). The password will be shared during the workshop. You can also create your own free keys here (it requires creating an account):\n",
    "\n",
    "- https://currentsapi.services/en\n",
    "- https://huggingface.co/\n",
    "\n",
    "Then execute the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMmjpIjK6a1q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = userdata.get('HUGGINGFACE_API_KEY')\n",
    "os.environ[\"CURRENTS_API_KEY\"] = userdata.get('CURRENTS_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXT8U0ah6oAo"
   },
   "source": [
    "#### **[Only if you are using Jupyter Notebooks]** Setting up secrets\n",
    "\n",
    "Next, we need to set the secrets. You can find their values [here](https://privatebin.net/?ec00cd7f2c464e55#8xMHSFNHyTrGe8f1DhyB62qCmb9RwrPoFExV5pWKXZEs). The password will be shared during the workshop. You can also create your own free keys here (it requires creating an account):\n",
    "\n",
    "- https://currentsapi.services/en\n",
    "- https://huggingface.co/\n",
    "\n",
    "Set the secrets values in `helper_secrets.py`. Then execute the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AqAKbjWx69GW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import helper_secrets\n",
    "\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = helper_secrets.HUGGINGFACE_API_KEY\n",
    "os.environ[\"CURRENTS_API_KEY\"] = helper_secrets.CURRENTS_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHifw0hiUqf2"
   },
   "source": [
    "#### Exercise 1 (a): Setup and call the HuggingFace Client using Dapr Agents\n",
    "\n",
    "Run the following piece of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0S3IdAw_RX6j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danaarsovska/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dapr_agents import HFHubChatClient\n",
    "from dapr_agents.types import UserMessage\n",
    "from prompty import Prompty\n",
    "\n",
    "llm = HFHubChatClient(\n",
    "    api_key=os.getenv(\"HUGGINGFACE_API_KEY\"),\n",
    "    model='microsoft/Phi-3-mini-4k-instruct'\n",
    "    )\n",
    "\n",
    "response = llm.generate(\n",
    "    messages=[UserMessage(\"What is the impact of AI on the news? Limit the output to 1 sentance.\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pPjGh_tQBPX"
   },
   "source": [
    "**Expected output:** The LLM will respond with an explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdjFJnLOQB4n"
   },
   "source": [
    "Next, let's analyze the response object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJ_lc7JfQHMK",
    "outputId": "97217afd-44fc-4875-9112-d58c10edae92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full response object: choices=[Choice(finish_reason='stop', index=0, message=MessageContent(content='AI has dramatically transformed the news industry by enabling automated content creation, personalized news delivery, trend prediction, and fact-checking, making the consumption and distribution of information more efficient and reliable.', role='assistant'), logprobs=None)] created=1747403832 id='' model='microsoft/Phi-3-mini-4k-instruct' object='chat.completion' usage={'completion_tokens': 45, 'prompt_tokens': 24, 'total_tokens': 69}\n",
      "Content: AI has dramatically transformed the news industry by enabling automated content creation, personalized news delivery, trend prediction, and fact-checking, making the consumption and distribution of information more efficient and reliable.\n",
      "Model used: microsoft/Phi-3-mini-4k-instruct\n",
      "Tokens used: 69\n"
     ]
    }
   ],
   "source": [
    "print(\"Full response object:\", response)\n",
    "print(\"Content:\", response.get_content())\n",
    "print(\"Model used:\", response.model)\n",
    "print(\"Tokens used:\", response.usage.get(\"total_tokens\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cUCjMbySGBG"
   },
   "source": [
    "#### Exercise 1 (b): Asking for current information\n",
    "\n",
    "Now let's try tweaking the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uzpf1-YuSI1h"
   },
   "outputs": [],
   "source": [
    "response = llm.generate(\n",
    "    messages=[UserMessage(\"Get me the news today.\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQ1aJ_E5UWI1",
    "outputId": "05b71c53-4182-4557-af1f-5bbe569a9476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but as an AI developed by Microsoft, I'm unable to provide real-time news updates. To check the latest news, I would recommend visiting reputable news websites, using a news aggregator app, or tuning into a trusted news channel. It's important to verify information from a variety of sources to get the most accurate and current updates.\n"
     ]
    }
   ],
   "source": [
    "print(response.get_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msnDXYROS7fc"
   },
   "source": [
    "**Expected output:** The LLM will not be able to fetch the latest news. Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tBHfDaKTDQy"
   },
   "source": [
    "#### Exercise 1 (c): Prompt engineering\n",
    "\n",
    "Try different prompts to understand prompt design:\n",
    "\n",
    "* Request a list\n",
    "* Return a single word\n",
    "* Ask for a creative story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "50bTbM4hS4vk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = llm.generate(\n",
    "    messages=[UserMessage(\"Give me a list of 5 random hobbies. Return just the hobby names.\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = llm.generate(\n",
    "    messages=[UserMessage(\"Write a short story about a lost key that opens a magical door in an ancient library.\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word = llm.generate(\n",
    "    messages=[UserMessage(\"What is one word that best describes the feeling of finishing a long project?\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_4iq4uAkUdLK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Painting\n",
      "- Gardening  \t    # I'm sorry, but it seems there was an error in my previous response regarding gardeners and their work hours; let’s clarify that: A gardener typically works full time during plant growing seasons (spring through fall) or part times depending on climate conditions for yearly maintenance tasks such as pruning trees/shrubs & mow lawn areas to keep them healthy throughout all four seasonal changes which can range from several weeks upwards into months at any given location around world where weather patterns vary greatly between regions within same hemisphere e g US vs\n"
     ]
    }
   ],
   "source": [
    "print(response.get_content())\n",
    "print(single_word.get_content())\n",
    "print(story.get_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yo-uLJ0GSK8N"
   },
   "source": [
    "#### Exercise 1 (d): Parameter tweaking\n",
    "\n",
    "You can also try experimenting with model parameters, for example:\n",
    "\n",
    "* set the temperature (A float value to control the temperature of the model. Used to optimize for consistency and creativity)\n",
    "* Optional: Re-initialze the client with a different model: https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5xvO5dsMTGeR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The advent and integration into society have had a significant influence in various aspects, including journalism. Here are some ways that artificial intelligence (AI) has affected how we consume information:\n",
      " 1- Automated reporting - News organizations use algorithms to generate basic reports about events such as sports scores or financial updates quickly without human intervention; this allows them more time for investigative work while still providing upfront coverage when needed immediately after an event occurs . These automations can also help reduce errors by eliminating potential biases from reporters who may unintentionally skew their stories based upon personal beliefs/opinions etc\n"
     ]
    }
   ],
   "source": [
    "response = llm.generate(\n",
    "    messages=[UserMessage(\"What is the impact of AI on the news?\")],\n",
    "    temperature=0.1\n",
    ")\n",
    "print(response.get_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WFXtP4pTLiZ"
   },
   "source": [
    "**Discussion**: What makes a good prompt? How do parameters affect output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a9nbyvpPuvG"
   },
   "source": [
    "#### Exercise 1 (e): Chat completion using a prompty file for context\n",
    "\n",
    "In Dapr Agents, we can use prompty to provide additional context/history to our LLM. Before running the cells below, analyze the contents of `prompt_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "GOKWlHiuYPx8"
   },
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"\n",
    "---\n",
    "name: Basic Prompt\n",
    "description: A basic prompt that uses the chat API to answer questions\n",
    "model:\n",
    "    api: chat\n",
    "    configuration:\n",
    "        type: huggingface\n",
    "        name: microsoft/Phi-3-mini-4k-instruct\n",
    "    parameters:\n",
    "        max_tokens: 128\n",
    "        temperature: 0.2\n",
    "inputs:\n",
    "  question:\n",
    "    type: string\n",
    "sample:\n",
    "  \"question\": \"Who is the most famous person in the world?\"\n",
    "---\n",
    "system:\n",
    "You are an AI assistant who helps people find information.\n",
    "As the assistant, you answer questions briefly, succinctly.\n",
    "\n",
    "user:\n",
    "{{question}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Wfb6nFMQZjJ",
    "outputId": "9271470c-8ef9-46ec-8d76-52a81643565f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choices=[Choice(finish_reason='length', index=0, message=MessageContent(content=\"I'm Phi and this chatbot was created by Microsoft to assist with various inquiries across a wide range of topics including technology support for Windows PCs or Mac computers running on macOS Big Sur 12 beta versions (including Mojave). My primary goal as part-time tech assistance team member at Apple Inc., alongside my colleagues from Google LLC’S DeepMind division working together under their joint venture called 'Microsoft Research', has been helping users troubleshoot issues related specifically towards software applications like Safari browser version compatibility problems between different operating systems such iOS devices versus older ones still using OS X\", role='assistant'), logprobs=None)] created=1747404156 id='' model='microsoft/Phi-3-mini-4k-instruct' object='chat.completion' usage={'completion_tokens': 128, 'prompt_tokens': 36, 'total_tokens': 164}\n"
     ]
    }
   ],
   "source": [
    "llm = HFHubChatClient.from_prompty(prompt_text)\n",
    "print(llm.generate(input_data={\"question\":\"What is your name?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ft_ztIwTZb0x"
   },
   "source": [
    "Change the system instructions to make the assistant more formal, humorous, or detailed. Then re-execute the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Troubleshooting\n",
    "\n",
    "1. **API Key Issues**: If you see an authentication error, verify your HuggingFace API key in the `helper_secrets.py` file\n",
    "2. **Python Version**: If you encounter compatibility issues, make sure you're using Python 3.10+\n",
    "3. **Environment Activation**: Ensure your virtual environment is activated before running examples\n",
    "4. **Import Errors**: If you see module not found errors, verify that `pip install -r requirements.txt` completed successfully"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
